{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.9"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer as CV\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.decomposition import LatentDirichletAllocation as LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#データセットを野球、宇宙、mac、windows,銃についての5つに設定\n",
    "categories = ['rec.sport.baseball','sci.space','comp.sys.mac.hardware', 'comp.windows.x','talk.politics.guns']\n",
    "\n",
    "news20 = fetch_20newsgroups(categories=categories)\n",
    "news = news20.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CV(max_df=0.5, min_df=5, stop_words='english')#max_difとmin_difa→あまりにも多すぎる単語と少なすぎる単語の除去。どの程度の値が良いのかの尺度は不明なので数値は先人の物\n",
    "cved = cv.fit_transform(news)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n                          evaluate_every=-1, learning_decay=0.7,\n                          learning_method='online', learning_offset=10.0,\n                          max_doc_update_iter=100, max_iter=10,\n                          mean_change_tol=0.001, n_components=4, n_jobs=None,\n                          perp_tol=0.1, random_state=None,\n                          topic_word_prior=None, total_samples=1000000.0,\n                          verbose=0)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#トピック数を(データセット数-1)の4に設定、methodのonlineは処理の高速化のため\n",
    "lda = LDA(n_components=4,learning_method = 'online')\n",
    "lda.fit(cved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "topic #0\ngun, com, people, don, writes, article, guns, like, think, right, just, government, control, time, state, firearms, weapons, law, use \n\ntopic #1\ncom, nntp, host, mac, writes, university, apple, article, know, like, just, problem, drive, does, don, thanks, use, computer, ve \n\ntopic #2\nfile, space, com, window, nasa, program, use, server, available, information, mit, motif, gov, entry, output, data, using, widget, sun \n\ntopic #3\nwrites, article, year, com, university, space, just, like, don, think, good, nntp, host, team, cs, baseball, game, better, know \n\n"
    }
   ],
   "source": [
    "features = cv.get_feature_names()\n",
    "\n",
    "#↓ここに書いてることは相変わらずわからんチン\n",
    "for tn in range(4):#トピック数分だけ繰り返し\n",
    "    print(\"topic #\"+str(tn))\n",
    "    row = lda.components_[tn]#トピックの番号tn？\n",
    "    words = ', '.join([features[i] for i in row.argsort()[:-20:-1]])#多分20までよびだしだけどあんま良くわからん\n",
    "    print(words, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}