{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.9"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer as CV\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.decomposition import LatentDirichletAllocation as LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "news20 = fetch_20newsgroups()\n",
    "news = news20.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n                          evaluate_every=-1, learning_decay=0.7,\n                          learning_method='online', learning_offset=10.0,\n                          max_doc_update_iter=100, max_iter=10,\n                          mean_change_tol=0.001, n_components=10, n_jobs=None,\n                          perp_tol=0.1, random_state=None,\n                          topic_word_prior=None, total_samples=1000000.0,\n                          verbose=0)"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 単語の出現頻度データを作成\n",
    "cv = CV(max_df=0.9, min_df=5, stop_words='english')#ここもわけわからん。特にmax_difとmin_dif\n",
    "cved = cv.fit_transform(news)\n",
    "len(cv.get_feature_names())\n",
    "\n",
    "# LDAのモデル作成と学習\n",
    "lda = LDA(learning_method = 'online')\n",
    "lda.fit(cved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "topic #0\nedu, space, nasa, university, information, research, program, use, posting, send, gov, science, new, available, data, host, software, nntp, center \n\ntopic #1\nedu, writes, article, com, just, don, like, posting, think, nntp, host, university, ca, good, know, cs, time, year, team \n\ntopic #2\nax, max, g9v, b8f, a86, 145, 0d, pl, 1d9, 34u, 0t, 3t, 75u, 1t, 2di, bhj, _o, giz, 6ei \n\ntopic #3\nedu, windows, university, host, posting, nntp, problem, thanks, use, like, know, window, does, ac, card, dos, help, using, uk \n\ntopic #4\ngod, edu, people, think, does, jesus, don, say, believe, com, writes, know, just, christian, like, article, bible, way, life \n\ntopic #5\ncom, key, use, chip, drive, file, data, scsi, access, encryption, available, mit, bit, clipper, information, number, used, disk, mac \n\ntopic #6\npeople, gun, said, com, turkish, armenian, don, like, armenians, know, guns, did, children, right, time, war, killed, world, weapons \n\ntopic #7\n25, db, 10, 17, 11, 14, 16, 55, 24, cx, 27, 34, 12, 13, 15, 45, 18, nec, 37 \n\ntopic #8\ngovernment, people, israel, law, edu, president, writes, article, state, mr, think, israeli, clinton, rights, com, public, don, make, right \n\ntopic #9\ncom, 00, car, new, edu, 10, distribution, article, posting, 20, nntp, host, 15, bike, hp, dod, writes, gov, ___ \n\n"
    }
   ],
   "source": [
    "features = cv.get_feature_names()\n",
    "\n",
    "\n",
    "#↓ここに書いてることよくわからんチン\n",
    "for tn in range(10):\n",
    "    print(\"topic #\"+str(tn))#というかここから下がどうなってるかわからん\n",
    "    row = lda.components_[tn]\n",
    "    words = ', '.join([features[i] for i in row.argsort()[:-20:-1]])\n",
    "    print(words, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}